{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8p2RCA3Qgae",
        "outputId": "8128da6d-b468-495f-b933-8de3c237a510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (5.2.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.4.1+cu121)\n",
            "Requirement already satisfied: packaging>=17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom, monai\n",
            "Successfully installed monai-1.4.0 pydicom-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install monai nibabel torchvision pydicom"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKfsCyp4Uf8v",
        "outputId": "8e19c97e-72e8-434e-8c54-908cd6c5a972"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.1)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (0.11.8)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.10.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "MJqwYdiIQgai"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import numpy as np\n",
        "import pydicom\n",
        "\n",
        "import torch\n",
        "import nibabel as nib\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as L\n",
        "\n",
        "from monai.transforms import Compose, RandRotate90d, RandFlipd, RandZoomd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_dir = '/content/drive/MyDrive/FLAIR'\n",
        "nifti_output_path = '/content/drive/MyDrive/NIFTI/output.nii.gz'"
      ],
      "metadata": {
        "id": "kPDZ_zu9RGHq"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory = '/content/drive/MyDrive/NIFTI'\n",
        "files = os.listdir(directory)\n",
        "print(f\"Files in {directory}:\")\n",
        "for file in files:\n",
        "    print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsz7mmQ5bcHh",
        "outputId": "a8baf970-c561-4ffa-8759-a27887752cb5"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in /content/drive/MyDrive/NIFTI:\n",
            "output.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dicom_dir = '/content/drive/MyDrive/FLAIR'\n",
        "if os.path.exists(dicom_dir):\n",
        "    print(f\"The DICOM directory exists at {dicom_dir}\")\n",
        "    print(\"Files in the directory:\")\n",
        "    for file in os.listdir(dicom_dir):\n",
        "        print(file)\n",
        "\n",
        "\n",
        "\n",
        "else:\n",
        "    print(f\"The DICOM directory does not exist at {dicom_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VOThaCxbgzm",
        "outputId": "63391040-87ee-438e-f738-1ae01824ba36"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DICOM directory exists at /content/drive/MyDrive/FLAIR\n",
            "Files in the directory:\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0011.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0019.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0004.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0008.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0007.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0017.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0003.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0013.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0015.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0018.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0006.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0016.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0002.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0020.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0021.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0009.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0005.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0001.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0012.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0014.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0022.dcm\n",
            "BRAINIX_DICOM_FLAIR_IM-0001-0010.dcm\n",
            ".DS_Store\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion from dicom to nifti\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "\n",
        "def dicom_to_nifti(dicom_dir, nifti_output_path):\n",
        "    slices = []  # will store the pixel data from dicom files\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(os.path.dirname(nifti_output_path), exist_ok=True)\n",
        "\n",
        "    for s in sorted(os.listdir(dicom_dir)):  # Sort to ensure correct slice order\n",
        "        if s.endswith('.dcm'):\n",
        "            dcm_path = os.path.join(dicom_dir, s)\n",
        "            dcm = pydicom.dcmread(dcm_path)\n",
        "            slices.append(dcm.pixel_array)\n",
        "\n",
        "    if not slices:\n",
        "        raise ValueError(f\"No DICOM files found in {dicom_dir}\")\n",
        "\n",
        "    volume = np.stack(slices, axis=-1)  # created 3d volume by stacking the np arrays\n",
        "    nifti_img = nib.Nifti1Image(volume, affine=np.eye(4))  # NIFTI object conversion\n",
        "    nib.save(nifti_img, nifti_output_path)  # saving\n",
        "    print(f\"NIFTI file saved at {nifti_output_path}\")\n",
        "\n",
        "dicom_dir = '/content/drive/MyDrive/FLAIR'\n",
        "\n",
        "\n",
        "nifti_output_path = '/content/drive/MyDrive/NIFTI/output.nii.gz' # NIFTI Files here lessgoo\n",
        "\n",
        "\n",
        "# Run the conversion\n",
        "try:\n",
        "    dicom_to_nifti(dicom_dir, nifti_output_path)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during conversion: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZGCt0u0bqE_",
        "outputId": "f825413b-d15f-4aee-b99f-93e303a4367b"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NIFTI file saved at /content/drive/MyDrive/NIFTI/output.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rfTo_wWQwXL",
        "outputId": "2edd75d1-8f53-4070-80ba-db4a9fb88ea1"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "mkBprqd2Qgaj"
      },
      "outputs": [],
      "source": [
        "def normalise_volume(volume):\n",
        "    volume = (volume - np.mean(volume))/np.std(volume) # this is normalising along std and mean\n",
        "\n",
        "    return volume"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import Resize"
      ],
      "metadata": {
        "id": "XCbssmANUdFd"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset class"
      ],
      "metadata": {
        "id": "C-SUBb0kZe_v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "YfhFFvXhQgak"
      },
      "outputs": [],
      "source": [
        "# creating dataset class\n",
        "\n",
        "class MRI_Dataset(Dataset):\n",
        "    def __init__(self, nifti_files, transform=None, target_shape=(288, 288, 32)):\n",
        "        self.nifti_files = nifti_files\n",
        "        self.transform = transform\n",
        "        self.target_shape = target_shape # ensure that the target shape is 32 even when the 288 * 288 * 22 is padded here\n",
        "        self.resize = Resize(spatial_size=target_shape)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.nifti_files) # return the lenght\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        nifti_file = self.nifti_files[idx]\n",
        "        img = nib.load(nifti_file).get_fdata()\n",
        "        img = normalise_volume(img)\n",
        "        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
        "\n",
        "        # Pad the third dimension from 22 to 32\n",
        "        pad_size = self.target_shape[2] - img.shape[3]\n",
        "        img = torch.nn.functional.pad(img, (0, pad_size, 0, 0, 0, 0)) # padding\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, img  # input and target are the same for autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation"
      ],
      "metadata": {
        "id": "F0E0aRKlZhpj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "VHogi0psQgak"
      },
      "outputs": [],
      "source": [
        "# performing Data augmentation and transofmration\n",
        "\n",
        "import torch\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    RandRotate90,\n",
        "    RandFlip,\n",
        "    RandZoom,\n",
        "    EnsureType\n",
        ")\n",
        "\n",
        "transform = Compose([\n",
        "    EnsureType(),\n",
        "    RandRotate90(prob=0.5, spatial_axes=[0, 1]),\n",
        "    RandFlip(prob=0.5, spatial_axis=0),\n",
        "    RandZoom(prob=0.5, min_zoom=0.9, max_zoom=1.1),\n",
        "])\n",
        "\n",
        "dataset = MRI_Dataset(nifti_files=nifti_files, transform=transform, target_shape=(288, 288, 32))\n",
        "nifti_files = ['/content/drive/MyDrive/NIFTI/output.nii.gz']  # final nifti destination"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_dataset(dataset):\n",
        "    print(f\"Dataset length: {len(dataset)}\")\n",
        "    sample, _ = dataset[0]\n",
        "    print(f\"Sample shape: {sample.shape}\")\n",
        "    print(f\"Sample dtype: {sample.dtype}\")\n",
        "    print(f\"Sample min: {sample.min()}, max: {sample.max()}\")\n",
        "\n",
        "check_dataset(dataset)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)  # Batch size 1 for testing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL063Ba2bI8i",
        "outputId": "fbad2753-ff23-48a4-cc02-403efcb29802"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset length: 1\n",
            "Sample shape: torch.Size([1, 288, 288, 32])\n",
            "Sample dtype: torch.float32\n",
            "Sample min: -0.6572733521461487, max: 7.510774612426758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloader creation"
      ],
      "metadata": {
        "id": "c9MzYiyBZjsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset and dataloader\n",
        "dataset = MRI_Dataset(nifti_files=nifti_files, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "vVjZoSX7WUdR"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "wsLTkpmPQgal"
      },
      "outputs": [],
      "source": [
        "from monai.networks.nets import SwinUNETR\n",
        "\n",
        "model = SwinUNETR(\n",
        "    img_size=(288, 288, 32),  # Adjusted to match our padded input\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    feature_size=48,\n",
        "    drop_rate=0.0,\n",
        "    attn_drop_rate=0.0,\n",
        "\n",
        "    dropout_path_rate=0.0,\n",
        "    use_checkpoint=False, # no need for small dataset\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Imports swin unter and initialises the model\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "#loss fuinction\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4) # adam optimiser with lr\n",
        "\n",
        "\n",
        "# checks if cuda availane\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7x9yfV5WhwM",
        "outputId": "500aaa31-d6c8-4def-f5b3-2c9f50c8cd86"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SwinUNETR(\n",
              "  (swinViT): SwinTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv3d(1, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (layers1): ModuleList(\n",
              "      (0): BasicLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0-1): 2 x SwinTransformerBlock(\n",
              "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): MLPBlock(\n",
              "              (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
              "              (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
              "              (fn): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          (reduction): Linear(in_features=384, out_features=96, bias=False)\n",
              "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layers2): ModuleList(\n",
              "      (0): BasicLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0-1): 2 x SwinTransformerBlock(\n",
              "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): MLPBlock(\n",
              "              (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
              "              (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
              "              (fn): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          (reduction): Linear(in_features=768, out_features=192, bias=False)\n",
              "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layers3): ModuleList(\n",
              "      (0): BasicLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0-1): 2 x SwinTransformerBlock(\n",
              "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): MLPBlock(\n",
              "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
              "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              (fn): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          (reduction): Linear(in_features=1536, out_features=384, bias=False)\n",
              "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layers4): ModuleList(\n",
              "      (0): BasicLayer(\n",
              "        (blocks): ModuleList(\n",
              "          (0-1): 2 x SwinTransformerBlock(\n",
              "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): MLPBlock(\n",
              "              (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "              (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              (fn): GELU(approximate='none')\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          (reduction): Linear(in_features=3072, out_features=768, bias=False)\n",
              "          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (encoder1): UnetrBasicBlock(\n",
              "    (layer): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(1, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (encoder2): UnetrBasicBlock(\n",
              "    (layer): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (encoder3): UnetrBasicBlock(\n",
              "    (layer): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (encoder4): UnetrBasicBlock(\n",
              "    (layer): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (encoder10): UnetrBasicBlock(\n",
              "    (layer): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (decoder5): UnetrUpBlock(\n",
              "    (transp_conv): Convolution(\n",
              "      (conv): ConvTranspose3d(768, 384, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "    )\n",
              "    (conv_block): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(768, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(768, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (decoder4): UnetrUpBlock(\n",
              "    (transp_conv): Convolution(\n",
              "      (conv): ConvTranspose3d(384, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "    )\n",
              "    (conv_block): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(384, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(384, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (decoder3): UnetrUpBlock(\n",
              "    (transp_conv): Convolution(\n",
              "      (conv): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "    )\n",
              "    (conv_block): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (decoder2): UnetrUpBlock(\n",
              "    (transp_conv): Convolution(\n",
              "      (conv): ConvTranspose3d(96, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "    )\n",
              "    (conv_block): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (decoder1): UnetrUpBlock(\n",
              "    (transp_conv): Convolution(\n",
              "      (conv): ConvTranspose3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
              "    )\n",
              "    (conv_block): UnetResBlock(\n",
              "      (conv1): Convolution(\n",
              "        (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (conv2): Convolution(\n",
              "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
              "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "      (conv3): Convolution(\n",
              "        (conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "      )\n",
              "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    )\n",
              "  )\n",
              "  (out): UnetOutBlock(\n",
              "    (conv): Convolution(\n",
              "      (conv): Conv3d(48, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkNh5sHkbX4K",
        "outputId": "6c88ca43-d140-45dd-e2f3-bccd209a0503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([1, 1, 288, 288, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verifying is file exists\n",
        "\n",
        "import os\n",
        "\n",
        "nifti_file_path = '/content/drive/MyDrive/NIFTI/output.nii.gz'\n",
        "if os.path.exists(nifti_file_path):\n",
        "    print(f\"The file exists at {nifti_file_path}\")\n",
        "else:\n",
        "    print(f\"The file does not exist at {nifti_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ts4pEPUW_CT",
        "outputId": "592225b1-9df0-44ae-df14-ce9f2ffad578"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file exists at /content/drive/MyDrive/NIFTI/output.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some image checking -\n",
        "\n",
        "img = nib.load(nifti_file_path).get_fdata()\n",
        "print(img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-wUK8kVZGMW",
        "outputId": "2a34b3d0-bc4c-4cc8-d09d-b0af37ad8647"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(288, 288, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "dH57b5xncFjA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test a single batch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "test_input, _ = next(iter(dataloader))\n",
        "test_input = test_input.to(device)\n",
        "print(f\"Input shape: {test_input.shape}\")\n",
        "try:\n",
        "    test_output = model(test_input)\n",
        "    print(f\"Output shape: {test_output.shape}\")\n",
        "    print(\"Model successfully processed the input\")\n",
        "except Exception as e:\n",
        "    print(f\"Error occurred: {str(e)}\")\n",
        "\n",
        "\n",
        "    # the testing failed as the MRI images are too large for my ram to process at this point\n",
        "    # also worked with pytorch lightning and created custom data module and lightning module to fit the model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "NXV00TXocc6J",
        "outputId": "e3c20a3e-1d50-481d-848e-4fc4d1784c47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4a69ea79055a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test a single batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nasic traiing loop here\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch: {epoch}, Batch idx: {batch_idx}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "g6gfgvOSX515"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "parthpython",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}